<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-09-02T17:15:57-07:00</updated><id>/feed.xml</id><title type="html">Keith Matthews</title><subtitle>This is a site I plan on using to showcase my work and projects im involved with.</subtitle><entry><title type="html">Ansible Auto Patching</title><link href="/2024/09/02/Ansible-auto-patching.html" rel="alternate" type="text/html" title="Ansible Auto Patching" /><published>2024-09-02T00:00:00-07:00</published><updated>2024-09-02T00:00:00-07:00</updated><id>/2024/09/02/Ansible-auto-patching</id><content type="html" xml:base="/2024/09/02/Ansible-auto-patching.html"><![CDATA[<h3 id="goals">Goals:</h3>

<ul>
  <li>Create inventory of devices present in the micro space in development and production clusters</li>
  <li>Run automated daily updates of development cluster of machines</li>
  <li>Run automated once a week updates of production machines</li>
  <li>Log information about updates</li>
  <li>notifications pushed to discord channel with stats on updates along with any required reboots of infrastructure</li>
</ul>

<h3 id="list-of-machines">list of machines:</h3>

<p>Development:
	- dev-nas1 (planned)
	- dev-compute1
	- dev-compute2
	- dev-gpu-compute1
Production
	- prod-nas1
	- prod-playbook-runner-compute1
	- prod-compute2
Network Devices:
	- mikrotik1</p>

<h3 id="steps-to-complete">Steps to complete:</h3>

<ul>
  <li>the following needs to be true on all machines
    <ul>
      <li>I need to be able to login using ssh</li>
      <li>The machine needs to have the borg user</li>
      <li>the borg user needs the following
        <ul>
          <li>No password sudo privileges</li>
          <li>ssh public keys for the machine that will run the ansible playbooks</li>
          <li>secure password (saved in Micro Space password vault)</li>
          <li>ssh daemon needs to be restarted to apply changes</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>While I am in any machine, I fixed any minor configuration issues having to do with my access. on some machines I had set all sudo group members have no password access. this was an artifact of early experimentation with ansible on my part and was insecure. These problems have been rectified.</li>
</ul>

<hr />

<p>Now that the machines are all functional and able to talk together development of the ansible playbooks can begin.</p>

<ul>
  <li>
    <p>Decide on structure of file system for machine that will run ansible playbooks. that looks like this
<img src="/images/ansible-patching-tree.png" alt="tree output" /></p>
  </li>
  <li>Develop Playbooks for development and production clusters. these will largely be the same but with different variables plugged in. They need to be two separate playbooks due to the different timelines each is run under. Cron jobs will be used to deploy playbooks on their schedules.</li>
  <li>Build/use standard plays to run updates on remote Linux systems</li>
  <li>get Cron jobs working
    <ul>
      <li>Originally I was considering using a tool called semaphore UI primarily for the scheduling tools used to run ansible playbooks or other IAC tasks along with UI triggers and other things. this tool seems like the portainer of the ansible/terraform/opentofu world and while it looked neat and I will likely circle back to it at some point I decided that the management overhead for using this tool and getting it setup was more than I wanted to mess with at this point. Cron seems like plenty enough to run daily and weekly update/upgrade tasks. If I decide to move this all to semaphore-UI in the future there shouldn’t be a ton of additional work to make that happen.</li>
      <li>This was pretty straight forward. I followed a guide from phoenix systems to setup crontab. I set it up to run a simple playbook once every couple of minutes and was able to observe logs being generated.</li>
      <li>The server running the ansible playbooks is on UTC time so I set the Cron jobs to run at 10:00 UTC which is around 2-3 in the morning in the pacific timezone where these servers exist so the updates don’t interrupt others working in the micro space.</li>
      <li>The production machines will be at the same time but their Cron jobs will run on Sunday nights (this might change to Monday nights, need to talk with more experienced sys-admins about that)</li>
    </ul>
  </li>
  <li>Add Logging functionality
    <ul>
      <li>the bulk of the playbooks to run these updates are tasks to properly complete the logging of the updates run on these servers.</li>
      <li>since all the servers run Debian the apt package manager was easy to setup and pull data from using the regex search function</li>
      <li>the playbooks register the output of the update step and the check if a reboot is required and starts to work with that data.
        <ol>
          <li>create a folder for the day the update runs in either the dev or prod folder</li>
          <li>save a .log file to the local host with just the hostname number of upgraded, newly installed, removed, and held packages, and if the reboot_required file exists.</li>
          <li>save a .vlog file to the local host with the entire standard output from ansible with the results of the update command.</li>
          <li>register the .log files saved to the local host to work with them via ansible</li>
          <li>echo the log file contents into a single file</li>
          <li>convert the log file into a string</li>
          <li>other processes are engaged. more on them shortly. after those steps are done the .log files get deleted but the .vlog files stay for later review of what was updated on remote systems since those packages are named.</li>
        </ol>
      </li>
      <li>It should be noted that the logging steps almost all happen on the machine that runs all the ansible playbooks. While not implemented, this will likely make it easy to ship these log files off to a NAS that can archive them or use them as data points for Grafana. that is out of the scope of this whole thing but will be worked on later.</li>
    </ul>
  </li>
  <li>Add notifications
    <ul>
      <li>This was much more simple than I expected. Since the members of the micro space use discord for general communications I wanted to implement daily notifications of what systems got updated and how many updates got deployed along with the information on what servers are due for a reboot due to kernel updates.</li>
      <li>I setup a channel in the discord server and setup a simple webhook integration. copying over the link and then using the community.general.discord module allowed me to send the contents of the combined log file as an embedded message with all the info for all machines in the dev or production cluster. there is also some additional tweaks made to the simple webhook push to truncate the amount of characters (it seems there’s a limit of 1000 characters per message. this could be negated by building a discord bot but that is out of scope at this time.)</li>
      <li>This webhook solution kind of just works and didn’t need a ton in the way of configuration. the bulk of the challenge here was figuring out how to format the message and the logs in such a way that they were brief and to the point.</li>
    </ul>
  </li>
  <li>Get Open Media Vault working.
    <ul>
      <li>This was largely the same as running updates for everything else but with a few caveats</li>
      <li>the main one was that the open media vault machine, while it contains the apt package manager, really relies on the <code class="language-plaintext highlighter-rouge">omv-upgrade</code> tool to run all necessary updates from the CLI or in an automated fashion. there may be an API but I don’t think ansible has been regularly used with open media vault so I kinda had to figure this out on my own</li>
      <li>What I figured out was that the <code class="language-plaintext highlighter-rouge">omv-upgrade</code> tool is used to upgrade the system and then <code class="language-plaintext highlighter-rouge">omv-salt deploy run --append-dirty</code> to apply the pending changes (that yellow banner that shows up at the top of the page any time you change something in open media vault)</li>
      <li>I could possibly setup the OMV7 steps to reside inside the play to update the regular Linux hosts but that would have been much more invasive and would likely have required I test against real hosts which I’m trying to avoid with the production network as much as possible.</li>
      <li>development for this portion was done on my local network targeting an OMV7 virtual machine</li>
    </ul>
  </li>
  <li>Network devices
    <ul>
      <li>I decided that with the progress other members of the micro space are making into logging with Grafana and specifically with that in conjunction with mikrotik devices, coupled with the fact that mikrotik devices are updated infrequently, I don’t think scheduled update and notification steps are necessary in the same way the Linux systems get daily package updates</li>
      <li>I do have updates of the mikrotik infrastructure using ansible working so I think that the workflow there will either be using Grafana to notify when updates are available for those pieces of infrastructure and then one of the admins responsible for that equipment will either just apply updates via the mikrotik dashboard or they can login to the ansible playbook machine and manually run the update playbooks. this will need to be a thing that is done with care because updating the mikrotik equipment brings down the network the Micro Space runs in for 5-10 minutes which is rude</li>
    </ul>
  </li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<p>I learned a lot with this lab. I think that in the future, while all the logging stuff was/is very cool and does work, using tools like Prometheus and Grafana make more sense for alerting and there is likely a way to use those tools and their functions to more effectively do the logging and messaging than what I built here. That being said, I am really proud of this set of playbooks and I think it taught me a lot of valuable information that I can go on to use with ansible in the future and I got a better Idea of the bigger devops picture that exists. The update portion of this task is working and it is something that could be tied into with other sorts of tools down the line. running ansible playbooks from a dashboard based on different alerts to various sysadmins is a thing that is coming to the micro space.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Goals:]]></summary></entry><entry><title type="html">Ceph Ansible Lab</title><link href="/2024/08/20/Ceph-Ansible-Lab.html" rel="alternate" type="text/html" title="Ceph Ansible Lab" /><published>2024-08-20T00:00:00-07:00</published><updated>2024-08-20T00:00:00-07:00</updated><id>/2024/08/20/Ceph-Ansible-Lab</id><content type="html" xml:base="/2024/08/20/Ceph-Ansible-Lab.html"><![CDATA[<h3 id="goal">Goal:</h3>

<p>Follow along with a recent Network Chuck video on Ceph Clustering but use Ansible as much as possible to implement the lab. Follow along with his setup instructions but use ansible where possible to provision and configure machines.</p>

<h3 id="definitions">Definitions:</h3>

<p>Ceph: (Per <a href="https://ceph.io/en/">https://ceph.io/en/</a>) “Ceph is an open-source, distributed storage system”</p>

<p>Ansible: (Per <a href="https://www.ansible.com/">https://www.ansible.com/</a>) “Ansible is an open source IT automation engine that automates provisioning, configuration management, application deployment, orchestration, and many other IT processes. It is free to use, and the project benefits from the experience and intelligence of its thousands of contributors.”</p>

<h3 id="code">Code!</h3>

<p>Checkout the code I created and worked on to complete this project at my ansible github repo!</p>

<p><a href="https://github.com/kmatthews123/ansible">https://github.com/kmatthews123/ansible</a></p>

<h3 id="planned-steps-for-lab">Planned Steps for lab:</h3>

<ol>
  <li>
    <p>Provision Virtual Machines</p>

    <ol>
      <li>
        <p>follow the included spreadsheet</p>
      </li>
      <li>
        <p>install operating system to each machine per diagram, run updates</p>
      </li>
      <li>
        <p>setup default user on each machine and import GitHub ssh keys for that user, the keithm username with a simple password to get started and will not be online until ready to deploy new credentials via ansible. Use a secure pasword for the machine that will be running ansible playbooks against other hosts/</p>
      </li>
      <li>
        <p>setup host-names and IP addresses for each host.</p>
      </li>
      <li>
        <p>setup ssh connection between the machine that will be the ansible host (ubuntu-server6) and all the CEPH workers/ansible targets (this will require you turn on ssh password connection briefly. turn this back off when done)</p>
      </li>
      <li>
        <p>once all the basic provisioning is complete, turn off the 3 physical machines, and take a snapshot of the VM’s, these will be used while testing the ansible implementation to prevent unintended data loss</p>
      </li>
    </ol>
  </li>
</ol>

<table>
  <thead>
    <tr>
      <th>server NUM</th>
      <th>Host OS</th>
      <th>Host Hardware</th>
      <th>Hostname</th>
      <th>Ethernet Adapter</th>
      <th>IP address</th>
      <th>added storage</th>
      <th>roles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>server 1:</strong></td>
      <td><strong>ubuntu 22.04</strong></td>
      <td>VM, 2GB RAM, 2 Core</td>
      <td>ubuntu-server1</td>
      <td>enp0s3</td>
      <td><strong>192.168.86.101</strong></td>
      <td>iscsi1, iscsi2</td>
      <td>ansible target, testing: ceph manager final: ceph worker</td>
    </tr>
    <tr>
      <td><strong>server 2:</strong></td>
      <td><strong>ubuntu 22.04</strong></td>
      <td>VM, 2 GB RAM, 2 Core</td>
      <td>ubuntu-server2</td>
      <td>enp0s3</td>
      <td><strong>192.168.86.102</strong></td>
      <td>iscsi3</td>
      <td>ansible target, ceph worker</td>
    </tr>
    <tr>
      <td><strong>server 3:</strong></td>
      <td><strong>ubuntu 22.04</strong></td>
      <td>Zimaboard 832</td>
      <td>ubuntu-server3</td>
      <td>enp0s2  enp0s3    (dhcp)</td>
      <td><strong>192.168.86.103</strong></td>
      <td>iscsi4, 500gb ssd, 500gb hdd</td>
      <td>ansible target, ceph manager/worker</td>
    </tr>
    <tr>
      <td><strong>server 4:</strong></td>
      <td><strong>ubuntu 20.04</strong></td>
      <td>Raspberry Pi4</td>
      <td>ubuntu-server4</td>
      <td>eth0</td>
      <td><strong>192.168.86.104</strong></td>
      <td>iscsi5</td>
      <td>ansible target, ceph worker</td>
    </tr>
    <tr>
      <td><strong>server 5:</strong></td>
      <td><strong>ubuntu 20.04</strong></td>
      <td>Raspberry Pi 3</td>
      <td>ubuntu-server5</td>
      <td>eth0</td>
      <td><strong>192.168.86.105</strong></td>
      <td>iscsi6</td>
      <td>ansible target, ceph worker</td>
    </tr>
    <tr>
      <td><strong>server 6:</strong></td>
      <td><strong>ubuntu 24.04</strong></td>
      <td>VM, 4 GB RAM, 4 Core</td>
      <td>ubuntu-server6</td>
      <td> </td>
      <td><strong>192.168.86.106</strong></td>
      <td>N/A</td>
      <td>ansible controller</td>
    </tr>
  </tbody>
</table>

<ol>
  <li>
    <p>provision ISCSI on NAS ( TrueNAS-scale ) per the below list (I don’t have any external drives to use for this project) ISCSI drives are sufficient to test with and adds the challenge of setting up the drives on each host.</p>

    <ol>
      <li>
        <p>iscsi1 - 200gb  VM1</p>
      </li>
      <li>
        <p>iscsi2 - 100gb VM1</p>
      </li>
      <li>
        <p>iscsi3 - 100gb Pi4</p>
      </li>
      <li>
        <p>iscsi4 - 100gb Pi3</p>
      </li>
      <li>
        <p>iscsi5 - 120gb VM2</p>
      </li>
      <li>
        <p>iscsi6 - 85gb VM2</p>
      </li>
    </ol>
  </li>
  <li>
    <p>setup HAPac2 Mikrotik router to get physical machines on the network, This is also going to be a useful tool to diagnose network issues as they occur. refer to lab network diagram for network layout. In my case the network is not ideal for lab work but its what I’ve got</p>
  </li>
  <li>
    <p>learn how to complete the following steps with ansible</p>

    <ol>
      <li>
        <p>run updates and upgrades</p>
      </li>
      <li>
        <p>setup a new user on all hosts with unique, strong passwords. delete bad password user.</p>
      </li>
      <li>
        <p>setup ssh as root (modify /etc/sshd.config) add root ssh key from ubuntu-server3 to all hosts (per network chuck ceph video though this is insecure as far as I know)</p>
      </li>
      <li>
        <p>mount iscsi drives on all systems</p>
      </li>
      <li>
        <p>prep drives (not the drive with the host os)</p>

        <ul>
          <li>
            <p>wipe out the disk (sgdisk –zap-all /dev/sd_ )</p>
          </li>
          <li>
            <p>wipe the file system (wipefs)</p>
          </li>
        </ul>
      </li>
      <li>
        <p>install dependent software on each system</p>

        <ul>
          <li>
            <p>docker</p>
          </li>
          <li>
            <p>lvm2 (should already be installed)</p>
          </li>
          <li>
            <p>open-iscsi (only needed in the case your using iscsi drives in the cluster)</p>
          </li>
          <li>
            <p>timedatectl status needs to be accurate (NTP synchronized and UTC time on all servers)</p>
          </li>
        </ul>
      </li>
      <li>
        <p>prep storage for ceph usage on all hosts</p>
      </li>
      <li>
        <p>set var for ceph_release</p>
      </li>
      <li>
        <p>install cephadm and make executeable after pulling down ceph repo to root user on</p>
      </li>
      <li>
        <p>cephadm bootstrap –mon-ip (ip address of manager)</p>
      </li>
      <li>
        <p>setup mon’s (these are monitors or managers of the cluster. you need a few of these for it to have proper redundancy)</p>
      </li>
      <li>
        <p>add osd’s (these are our drives essentially as I understand it)</p>
      </li>
    </ol>
  </li>
  <li>
    <p>once setup, play around with ceph, look at metrics, setup cephfs</p>
  </li>
</ol>

<h5 id="diagram-of-network">Diagram of network:</h5>

<p><img src="/images/ceph lab diagram.svg" alt="test" /></p>

<h3 id="results">Results:</h3>

<p>Overall I achieved my goals for this lab.</p>

<p>I think I got a better idea on using ansible to provision machines with software and setup basics stuff. I also learned about stuff that I will need to learn to get better at all of this.
those tools include:</p>

<ul>
  <li>
    <p>Key Management using Hashi-corp Vault, 1password, Bitwarden or Vaultwarden</p>
  </li>
  <li>
    <p>Cloud Init</p>
  </li>
  <li>
    <p>Teraform (IAC)</p>
  </li>
  <li>
    <p>Using ceph and understanding how it is used out in the wild.</p>
  </li>
  <li>
    <p>Virt-Manager for Linux based virtual machine management, specifically on remote hosts.</p>
  </li>
  <li>
    <p>understanding how ansible variables work and how they’re pulled into a playbook. I mostly understood this but there’s a lot more there to learn. Looks like there is a vs-code extension that could help with this called Ansible Variable Lookup though I haven’t used this yet.</p>
  </li>
</ul>

<p>A list of stuff I learned while completing this lab</p>

<ul>
  <li>
    <p>Setup TrueNAS served iscsi drives</p>
  </li>
  <li>
    <p>Using 1password CLI in tandem with bash scripting</p>
  </li>
  <li>
    <p>When a guide or documentation recommends opening up a root terminal before making a change there is probably a good reason for it</p>
  </li>
  <li>
    <p>PAM module and Yubi-key setup for a second factor on Linux</p>
  </li>
  <li>
    <p>Ansible</p>

    <ul>
      <li>
        <p>setup inventory files with hosts, host specific vars, and setting up nested group inventories</p>
      </li>
      <li>
        <p>using ansible vault files for playbook vars, calling specific vars in a loop, and other tasks for setting up users with secure credentials</p>
      </li>
      <li>
        <p>Ansible-Playbooks to:</p>

        <ul>
          <li>
            <p>run updates</p>
          </li>
          <li>
            <p>install software</p>
          </li>
          <li>
            <p>install docker</p>
          </li>
          <li>
            <p>install software that isn’t already in apts default repos</p>
          </li>
          <li>
            <p>set user time to all use UTC and ensure NTP time is enabled</p>
          </li>
          <li>
            <p>setup users with secure passwords that are stored at rest in encrypted vaults.</p>
          </li>
          <li>
            <p>create ssh keys and import them to all hosts so the ansible machine will always have access to those machines</p>
          </li>
          <li>
            <p>remove users that are on the systems</p>
          </li>
          <li>
            <p>pull in iscsi drives and mount them in the file system (this step the mount part specifically may have been what messed up the raspberry pi’s)</p>
          </li>
          <li>
            <p>format specific drives as specified by the host in the inventory file this could probably have been done better but it was towards the end of the project and I was just wanting to blast though.</p>
          </li>
          <li>
            <p>I messed around a bit with crowdsec, I think I have a good idea on what it does but it was distracting me from finishing the project so I put it to the side. Probably worth it to circle back on this.</p>
          </li>
          <li>
            <p>Install cephadm thought I think next time I will change the work flow to actually using cephadm from the machine that it is installed on That would have saved me a ton of time though the real answer is figure out ceph-ansible.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Setup ansible.cfg</p>
      </li>
      <li>
        <p>learn how to work with ansible-lint even though it sometimes doesn’t make much sense.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>bash scripting</p>
  </li>
  <li>
    <p>gpg generally and as a part of a script</p>
  </li>
  <li>
    <p>documentation and pre-planing/diagramming a network</p>
  </li>
</ul>

<p>I looked into the ceph-ansible tool and I struggled for 3 days to understand how to use it. at that point I chose to simply follow along with the Network Chuck video when it came to the steps included in actualy installing ceph on all the prepared hosts. I think that I need to re-approach that particular task with fresh eyes in a month or two. The final results of all this setup was a working ceph cluster though with a few detraction’s. for some reason, even though I was able to confirm that the drives were wiped and had nothing on them and they should have been visible to the cluster, the two raspberry pi devices did not want to play nice. They were able to join the cluster but they were not able to share their drives with the cluster. I couldn’t figure this out and Im going to chock it up to while it may be possible to use raspberry pi’s with ceph it is likely very unstable and probably shouldn’t be attempted in anything resembling production. An additional problem was the pi 3 on average took about 2-3 times as long to run any given command. Once setup cephadm was fairly straight forward to use. I was able to use the cephadm command line tool to bring in other hosts and I was also able to do that task with the dashboard that was setup using cephadm. As I said in the things I learned I think that I should have thought of the flow of this lab as though I had two admins. one doing the ansible side of things and one responsible for administering ceph. this would have the ansible host setup all hosts and got them prepped to be managed by the ceph administrator. This way the ceph admin would get keys to login to the ceph machine where they could have done the administration from. These two people could defiantly be the same person filling two different roles but if I had thought of things like this the workflow would have made a lot more sense. below is a diagram of this changed workflow.</p>

<p><img src="/images/ceph_lab_diagram_post_lab_edit.png" alt="Ceph Lab post build" /></p>

<h3 id="things-to-do-next-time">Things to do next time:</h3>

<ul>
  <li>
    <p>setup remote hosts targeted by anisble via tail-scale</p>
  </li>
  <li>
    <p>scripts for setup should be applicable to different networks and built in a way that makes them scale-able</p>
  </li>
  <li>
    <p>use a key-management utility</p>
  </li>
  <li>
    <p>update and configure Mikrotik router using ansible</p>
  </li>
  <li>
    <p>use more hosts</p>
  </li>
  <li>
    <p>do not use raspberry pi’s for this</p>
  </li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Controller</title><link href="/2024/06/25/controller.html" rel="alternate" type="text/html" title="Controller" /><published>2024-06-25T00:00:00-07:00</published><updated>2024-06-25T00:00:00-07:00</updated><id>/2024/06/25/controller</id><content type="html" xml:base="/2024/06/25/controller.html"><![CDATA[<h2 id="custom-hid-device-design">Custom HID device design</h2>

<p>This project was focused on designing and building a custom controller for use at my job and to learn how to use PCB design software.</p>

<p><a href="https://github.com/kmatthews123/Controller">GitHub - kmatthews123/Controller: Controller designed by me with code from Joystick_XL library</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Custom HID device design This project was focused on designing and building a custom controller for use at my job and to learn how to use PCB design software. GitHub - kmatthews123/Controller: Controller designed by me with code from Joystick_XL library]]></summary></entry><entry><title type="html">Octodocker</title><link href="/2024/06/25/octodocker.html" rel="alternate" type="text/html" title="Octodocker" /><published>2024-06-25T00:00:00-07:00</published><updated>2024-06-25T00:00:00-07:00</updated><id>/2024/06/25/octodocker</id><content type="html" xml:base="/2024/06/25/octodocker.html"><![CDATA[<h2 id="why-use-docker-for-3d-printing">Why use docker for 3d printing?</h2>

<p>Several years ago, I was told about docker while commiserating with a freind about the lack of raspberry pi devices or at least their massivly blown up price during the pandemic. My friend pointed out docker and it opened a world up. after lots of hours watching youtube videos, digging into guides and setup documentation and poking at some basic containers using the single rasperry pi I had in my posession I started my project. At the time I had a few things already running on that pi and I was going to use it to also host octoprint to help me in managing my ender 3 pro. While this would have been a good enough use case and I will get into some of the things I had to figure out to make this single install work, it became even more important when I gained an additional 3 3d printers from a friend. these machines, to be easily operated and maintaind also needed octoprint running. this was the true benifit of running octoprint in a container. Because this application is really light, while it is easier to install directly to an sd card and run it bare metal on a raspberry pi both because it requries connecting to usb and because it greatly simplifies connection to a camera for streaming (more on that later). From what I understand you can hook more than one usb up to a pi running octoprint bare metal but I havent seen many people use this method. I assume it is because octoprint really seems to be designed to run one printer. One rasperry pi for one printer at a time when a medium spec pi 4 was hanging out in the 200$ range if you could find them at all was a really steap ask. In retrospect a Pi 3 would have been cheaper and have run just fine but again, more on that later. When I set to adding the additional 3 printers to my fleet of machines, I started with first converting my original octoprint container from running off of a docker “one liner” and building a docker compose file for it. This process was really straight forward because the docker hub page for the octoprint app has a compose file right there. The things I had to add and modify were easy enough for the first machine, simply probe for and pass though the usb device and also give the web portal its own defined port. This process would become more dificult as I duplicated the docker compose file for the usb pass though which I will get to in a bit. the ports being duplicated was easy enough and I made things simple by using 4 adjacent ports with numbers 1-4 in order of the printers. As far as the usb connections go, the printers, running all at the same time are not capable of saturating the usb bus, and the main problem was that as you plug things in and un-plug things, the linux operating system will change the port numbers for each individual device. This is an issue because the decleration for which usb device bets passed into the docker container is static. it cannot tell the diffrence between two diffrent usb inputs as far as I can tell. I have a feeling that I could possibly figure out how to script a way of polling the 3d printer for some kind of finger print at the time of spinning up the docker container to grab the right usb device automaticly but I havent figured that out yet. for now what that means is each /dev/ttyusb gets passed into its own container correctly by simply shutting down all containers, unpluging all usb devices from the host system, and then adding the devices and starting the containers that corespond with that printer 1 at a time. this way the usb inputs are enumerated correctly to give each instance of octoprint the correct machine. this is a pretty hacky way of doing things but unless multiple 3d printers get unpluged at the same time it is pretty functional once setup.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Why use docker for 3d printing?]]></summary></entry><entry><title type="html">Projects Im Involved With</title><link href="/2024/06/25/projects-Im-involved-with.html" rel="alternate" type="text/html" title="Projects Im Involved With" /><published>2024-06-25T00:00:00-07:00</published><updated>2024-06-25T00:00:00-07:00</updated><id>/2024/06/25/projects-Im-involved-with</id><content type="html" xml:base="/2024/06/25/projects-Im-involved-with.html"><![CDATA[<h4 id="checkout-projects-im-involved-in">Checkout projects I’m involved in</h4>

<p>Robo Ruckus, I have asssited with testing, and development of alternative robotics platforms. I have also run many public displays of the robo ruckus games
<a href="https://www.roboruckus.com/">Robo Ruckus</a></p>

<p>Big Boat Energy, This project I worked on with a freind in bellingham, we designed and built a boat platform that can follow waypoint missions with minimal intervention.
<a href="https://github.com/BigBoatEnergy/boat-robot">Boatymcboatface</a></p>

<p>Raspberry Pi Club Jeopardy game, I assisted this group of BTC students by coming up a plethora of linux themed jeopardy questions. I also assisted with a hardware implementation to make deploying the game at an event.
<a href="https://github.com/btc-raspberrypiclub/jeopardy">Jeopardy</a></p>

<p>Ruby based Discord bot. this discord bot acts as the frontend for a Large Language model and allows users in a discord channel to interact with an “AI”. I assisted by testing the bot, and also adding the “nice message” function
<a href="https://github.com/joshbuker/discord-bot">Ruby Bot</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Checkout projects I’m involved in Robo Ruckus, I have asssited with testing, and development of alternative robotics platforms. I have also run many public displays of the robo ruckus games Robo Ruckus Big Boat Energy, This project I worked on with a freind in bellingham, we designed and built a boat platform that can follow waypoint missions with minimal intervention. Boatymcboatface Raspberry Pi Club Jeopardy game, I assisted this group of BTC students by coming up a plethora of linux themed jeopardy questions. I also assisted with a hardware implementation to make deploying the game at an event. Jeopardy Ruby based Discord bot. this discord bot acts as the frontend for a Large Language model and allows users in a discord channel to interact with an “AI”. I assisted by testing the bot, and also adding the “nice message” function Ruby Bot]]></summary></entry><entry><title type="html">Solartv</title><link href="/2024/06/25/solartv.html" rel="alternate" type="text/html" title="Solartv" /><published>2024-06-25T00:00:00-07:00</published><updated>2024-06-25T00:00:00-07:00</updated><id>/2024/06/25/solartv</id><content type="html" xml:base="/2024/06/25/solartv.html"><![CDATA[<p>Fixing a solar tv</p>

<p>This is a brief test article to explain how I was able to “fix” a “solar tv” that would normally be sold in Africa as best as I can tell. This tv has a drm lockout feature that uses the designers 12-volt power supply from a solar array and solar charge controller as the key to unlock the drm. As best as I can tell, either the 12-volt power supply has some kind of signal in the power that the tv can decode or there is a different cable used to unlock the tv assuming you have paid the company. For multiple reasons this bothers me so I took a bit of time to figure out what was going on here and how I could defeat it. I have a feeling that these TVs were purchased on Ali-express or a similar kind of site as it does not seem these things are sold normally in the US. I did not purchase these TVs but inherited them from a makerspace I was involved with, the story I got is someone got them off the back of a truck at burning man.</p>

<p>what first tipped me off to the tv having drm in the first place is that when turning on two of the several of these things I have access to they both had some strange behavior where the backlight would be on during initial power up, and then it would start flickering at a regular interval before shutting off altogether. at first this behavior looked like the tv was damaged and I put it aside and evaluated a second tv. When this second device exhibited the exact same behavior, I got very suspicious. I was powering the devices via a regular 12-volt dc barrel jack and adapter off the wall power. I knew that I was supplying enough current since the tv draws something like twelve volt thirteen watts and my 12-volt brick was rated for five amps of twelve volt, I tried with a second power supply that was rated for a similar power level. At this point I stopped and started googling the company that makes these things. I had help with this from my friend and we discovered that the manufacturer sells these devices as part of a solar electricity kit (more likely an addon to the base kits) in Africa. They have a payment plan system that I think is used to lock out users from their equipment if they do not have a current code. Id imagine that this lockout device is what’s used to plug the tv into power via the double sided 12 volt cable that came included with this machine, and then it sends some kind of handshake to the tv when powerup happens to verify you aren’t using just some random car battery and your sticking to their ecosystem. This sort of lockout is scummy in my opinion and it makes these TVs e-waste for me since I did not have the lockout device and no means of getting one outside of contacting the company, so I decided to keep digging. It turns out that this 12-volt tv is a pretty common piece of gear you can order from overseas. They seem useful for things like digital signage and storefronts where quality matters less than a variety mounting and power options for something that is going to display the same three things for its entire life. When I found a picture of the circuit boards in this style of 12-volt TVs, I decided to pop mine open as well and find out what was different.</p>

<p>Apon opening the tv I discovered that it appeared the main difference was the addition of a black PCB with the manufacturers name that brought in the “Inverter” wires (it’s all 12 volt so I’m not sure what’s getting “inverted” but that’s what the main board had as a label for that plug) and output 4 wires (2 black and 2 red and tied into the same plug) that traveled into the TVs body. I had a feeling these were the power wires for the backlight, but I was able to confirm this with a multimeter. during initial power up, the four wires showed a 9.75 - 10.25 DC potential over those two wires, the multimeter was a cheap one and the flickering was quick so the LEDs using the full twelve volts is not a huge leap. that power dropped off in time with the backlight going off on the monitor, so I was quite sure those four wires were for the LED backlight. The next step was to try and figure out how to defeat the lockout chip to get those LEDs on normally.</p>

<p>At this point I started poking around the little driver board that was between the tv backlight and the mainboard. This little board had several surface mount chips with one programable logic chip as its center. I was able to read the name of that chip, but I do not know enough to pull its code off. I also was working with a limited set of tools so ultimately; I focused on what was bringing the power into the board instead of trying to force the board itself to do something other than design. I probed the incoming eight “Inverter” wires from the main board and found that there were two that were carrying twelve volts directly from the power supply. There are other wires that are on and off at different voltage levels and for various times, these are used to tell the board what to do about power when the tv is plugged in but “turned off” via a remote or power button. This is because the mainboard is always powered and is always putting twelve volts out to the breakout “drm” board. My quick solution was to simply plug some jumpers between the twelve volts into the board and the LED plug. this did work but it does come with the drawback of the TVs backlight is always on. This is undesirable for obvious reasons in an off-grid type setup using something like solar or batteries but for my use case it does not matter. There is a compelling reason to get back in there and design some custom circuitry that could act to shut the tv on and off based on signal from the IR receiver but that is a problem for another day.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Fixing a solar tv This is a brief test article to explain how I was able to “fix” a “solar tv” that would normally be sold in Africa as best as I can tell. This tv has a drm lockout feature that uses the designers 12-volt power supply from a solar array and solar charge controller as the key to unlock the drm. As best as I can tell, either the 12-volt power supply has some kind of signal in the power that the tv can decode or there is a different cable used to unlock the tv assuming you have paid the company. For multiple reasons this bothers me so I took a bit of time to figure out what was going on here and how I could defeat it. I have a feeling that these TVs were purchased on Ali-express or a similar kind of site as it does not seem these things are sold normally in the US. I did not purchase these TVs but inherited them from a makerspace I was involved with, the story I got is someone got them off the back of a truck at burning man. what first tipped me off to the tv having drm in the first place is that when turning on two of the several of these things I have access to they both had some strange behavior where the backlight would be on during initial power up, and then it would start flickering at a regular interval before shutting off altogether. at first this behavior looked like the tv was damaged and I put it aside and evaluated a second tv. When this second device exhibited the exact same behavior, I got very suspicious. I was powering the devices via a regular 12-volt dc barrel jack and adapter off the wall power. I knew that I was supplying enough current since the tv draws something like twelve volt thirteen watts and my 12-volt brick was rated for five amps of twelve volt, I tried with a second power supply that was rated for a similar power level. At this point I stopped and started googling the company that makes these things. I had help with this from my friend and we discovered that the manufacturer sells these devices as part of a solar electricity kit (more likely an addon to the base kits) in Africa. They have a payment plan system that I think is used to lock out users from their equipment if they do not have a current code. Id imagine that this lockout device is what’s used to plug the tv into power via the double sided 12 volt cable that came included with this machine, and then it sends some kind of handshake to the tv when powerup happens to verify you aren’t using just some random car battery and your sticking to their ecosystem. This sort of lockout is scummy in my opinion and it makes these TVs e-waste for me since I did not have the lockout device and no means of getting one outside of contacting the company, so I decided to keep digging. It turns out that this 12-volt tv is a pretty common piece of gear you can order from overseas. They seem useful for things like digital signage and storefronts where quality matters less than a variety mounting and power options for something that is going to display the same three things for its entire life. When I found a picture of the circuit boards in this style of 12-volt TVs, I decided to pop mine open as well and find out what was different. Apon opening the tv I discovered that it appeared the main difference was the addition of a black PCB with the manufacturers name that brought in the “Inverter” wires (it’s all 12 volt so I’m not sure what’s getting “inverted” but that’s what the main board had as a label for that plug) and output 4 wires (2 black and 2 red and tied into the same plug) that traveled into the TVs body. I had a feeling these were the power wires for the backlight, but I was able to confirm this with a multimeter. during initial power up, the four wires showed a 9.75 - 10.25 DC potential over those two wires, the multimeter was a cheap one and the flickering was quick so the LEDs using the full twelve volts is not a huge leap. that power dropped off in time with the backlight going off on the monitor, so I was quite sure those four wires were for the LED backlight. The next step was to try and figure out how to defeat the lockout chip to get those LEDs on normally. At this point I started poking around the little driver board that was between the tv backlight and the mainboard. This little board had several surface mount chips with one programable logic chip as its center. I was able to read the name of that chip, but I do not know enough to pull its code off. I also was working with a limited set of tools so ultimately; I focused on what was bringing the power into the board instead of trying to force the board itself to do something other than design. I probed the incoming eight “Inverter” wires from the main board and found that there were two that were carrying twelve volts directly from the power supply. There are other wires that are on and off at different voltage levels and for various times, these are used to tell the board what to do about power when the tv is plugged in but “turned off” via a remote or power button. This is because the mainboard is always powered and is always putting twelve volts out to the breakout “drm” board. My quick solution was to simply plug some jumpers between the twelve volts into the board and the LED plug. this did work but it does come with the drawback of the TVs backlight is always on. This is undesirable for obvious reasons in an off-grid type setup using something like solar or batteries but for my use case it does not matter. There is a compelling reason to get back in there and design some custom circuitry that could act to shut the tv on and off based on signal from the IR receiver but that is a problem for another day.]]></summary></entry></feed>